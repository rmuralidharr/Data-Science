{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> (c) 2022 Tim C. Smith, All rights reserved\n",
    ">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gs999erazKxt",
    "tags": []
   },
   "source": [
    "# Universal Bank Promotional Campaign: A practical illustration of *model performance assessment using confusion matrices*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Problem Statement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Universal Bank has begun a program to encourage existing customers to borrow via a consumer loan program. \n",
    "\n",
    "The bank has tested a loan promotion on a random sample of 5000 customers. This test promotion resulted in 480 of the 5000 existing customers accepting the offer. \n",
    "\n",
    "The bank is intrigued by the success of this promotion. It has hired you to help them develop a model to identify which of its remaining customers may accept a similar promotion. \n",
    "\n",
    "They hired you to help them reduce the promotion costs and target the offer to only a subset of its customers that or more likely to accept the offer. They disclosed that the cost to promote this offer is \\\\$10 dollars per customer, and the profit from obtaining a loan customer is \\\\$100. They have an additional 50,000 customers that have not been contacted about the promotion. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import all required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing \n",
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Preliminary business problem scoping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before starting your analysis, you jot down what the profit and loss (P&L) must have been from their marking trial..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$-2,000.00\n"
     ]
    }
   ],
   "source": [
    "TP_profit = 100 - 10   # the loan profit minus the targeting cost\n",
    "FP_profit = -10   # no loan profit, just the targeting cost\n",
    "TN_profit = 0 # they wouldn't take a loan, and we didn't spend the money targeting them\n",
    "FN_profit = -100 # they would have taken the loan, but we didn't target them \n",
    "\n",
    "# in the null model there are only FP's and TP's because everyone is considered a possible customer\n",
    "original_profit = 480*TP_profit + (5000-480)*FP_profit\n",
    "print(f\"${original_profit:,.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using this approach on the remaining 50000 customers would not be a good business decision, as it would result in a loss of..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$-20,000.00\n"
     ]
    }
   ],
   "source": [
    "print(f\"${original_profit*50000/5000:,.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on this initial analysis, it's clear that the bank cannot continue this promotion unless they have a model to help them identify the best potential customers. The best model possible would be 100% accurate. Universal Bank's initial test resulted in 480 or 5000 customers choosing to take the offer. The rate 480/5000 is, therefore, the expected rate of customers that take the request, and thus the expected profit result from a perfectly accurate model would be:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$432,000.00\n"
     ]
    }
   ],
   "source": [
    "print(f\"${480*50000/5000*TP_profit:,.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Universal Bank is making the right decision in bringing you in to help them. You're probably now thinking you should renegotiate your constulting fee :)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load, Explore and Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Age</th>\n",
       "      <th>Experience</th>\n",
       "      <th>Income</th>\n",
       "      <th>ZIP Code</th>\n",
       "      <th>Family</th>\n",
       "      <th>CCAvg</th>\n",
       "      <th>Education</th>\n",
       "      <th>Mortgage</th>\n",
       "      <th>Personal Loan</th>\n",
       "      <th>Securities Account</th>\n",
       "      <th>CD Account</th>\n",
       "      <th>Online</th>\n",
       "      <th>CreditCard</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>49</td>\n",
       "      <td>91107</td>\n",
       "      <td>4</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>45</td>\n",
       "      <td>19</td>\n",
       "      <td>34</td>\n",
       "      <td>90089</td>\n",
       "      <td>3</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>39</td>\n",
       "      <td>15</td>\n",
       "      <td>11</td>\n",
       "      <td>94720</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>35</td>\n",
       "      <td>9</td>\n",
       "      <td>100</td>\n",
       "      <td>94112</td>\n",
       "      <td>1</td>\n",
       "      <td>2.7</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>35</td>\n",
       "      <td>8</td>\n",
       "      <td>45</td>\n",
       "      <td>91330</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>37</td>\n",
       "      <td>13</td>\n",
       "      <td>29</td>\n",
       "      <td>92121</td>\n",
       "      <td>4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>2</td>\n",
       "      <td>155</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>53</td>\n",
       "      <td>27</td>\n",
       "      <td>72</td>\n",
       "      <td>91711</td>\n",
       "      <td>2</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>50</td>\n",
       "      <td>24</td>\n",
       "      <td>22</td>\n",
       "      <td>93943</td>\n",
       "      <td>1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>35</td>\n",
       "      <td>10</td>\n",
       "      <td>81</td>\n",
       "      <td>90089</td>\n",
       "      <td>3</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>104</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>34</td>\n",
       "      <td>9</td>\n",
       "      <td>180</td>\n",
       "      <td>93023</td>\n",
       "      <td>1</td>\n",
       "      <td>8.9</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>65</td>\n",
       "      <td>39</td>\n",
       "      <td>105</td>\n",
       "      <td>94710</td>\n",
       "      <td>4</td>\n",
       "      <td>2.4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>29</td>\n",
       "      <td>5</td>\n",
       "      <td>45</td>\n",
       "      <td>90277</td>\n",
       "      <td>3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>48</td>\n",
       "      <td>23</td>\n",
       "      <td>114</td>\n",
       "      <td>93106</td>\n",
       "      <td>2</td>\n",
       "      <td>3.8</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>59</td>\n",
       "      <td>32</td>\n",
       "      <td>40</td>\n",
       "      <td>94920</td>\n",
       "      <td>4</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>67</td>\n",
       "      <td>41</td>\n",
       "      <td>112</td>\n",
       "      <td>91741</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>60</td>\n",
       "      <td>30</td>\n",
       "      <td>22</td>\n",
       "      <td>95054</td>\n",
       "      <td>1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>38</td>\n",
       "      <td>14</td>\n",
       "      <td>130</td>\n",
       "      <td>95010</td>\n",
       "      <td>4</td>\n",
       "      <td>4.7</td>\n",
       "      <td>3</td>\n",
       "      <td>134</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>42</td>\n",
       "      <td>18</td>\n",
       "      <td>81</td>\n",
       "      <td>94305</td>\n",
       "      <td>4</td>\n",
       "      <td>2.4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>46</td>\n",
       "      <td>21</td>\n",
       "      <td>193</td>\n",
       "      <td>91604</td>\n",
       "      <td>2</td>\n",
       "      <td>8.1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>55</td>\n",
       "      <td>28</td>\n",
       "      <td>21</td>\n",
       "      <td>94720</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ID  Age  Experience  Income  ZIP Code  Family  CCAvg  Education  Mortgage  \\\n",
       "0    1   25           1      49     91107       4    1.6          1         0   \n",
       "1    2   45          19      34     90089       3    1.5          1         0   \n",
       "2    3   39          15      11     94720       1    1.0          1         0   \n",
       "3    4   35           9     100     94112       1    2.7          2         0   \n",
       "4    5   35           8      45     91330       4    1.0          2         0   \n",
       "5    6   37          13      29     92121       4    0.4          2       155   \n",
       "6    7   53          27      72     91711       2    1.5          2         0   \n",
       "7    8   50          24      22     93943       1    0.3          3         0   \n",
       "8    9   35          10      81     90089       3    0.6          2       104   \n",
       "9   10   34           9     180     93023       1    8.9          3         0   \n",
       "10  11   65          39     105     94710       4    2.4          3         0   \n",
       "11  12   29           5      45     90277       3    0.1          2         0   \n",
       "12  13   48          23     114     93106       2    3.8          3         0   \n",
       "13  14   59          32      40     94920       4    2.5          2         0   \n",
       "14  15   67          41     112     91741       1    2.0          1         0   \n",
       "15  16   60          30      22     95054       1    1.5          3         0   \n",
       "16  17   38          14     130     95010       4    4.7          3       134   \n",
       "17  18   42          18      81     94305       4    2.4          1         0   \n",
       "18  19   46          21     193     91604       2    8.1          3         0   \n",
       "19  20   55          28      21     94720       1    0.5          2         0   \n",
       "\n",
       "    Personal Loan  Securities Account  CD Account  Online  CreditCard  \n",
       "0               0                   1           0       0           0  \n",
       "1               0                   1           0       0           0  \n",
       "2               0                   0           0       0           0  \n",
       "3               0                   0           0       0           0  \n",
       "4               0                   0           0       0           1  \n",
       "5               0                   0           0       1           0  \n",
       "6               0                   0           0       1           0  \n",
       "7               0                   0           0       0           1  \n",
       "8               0                   0           0       1           0  \n",
       "9               1                   0           0       0           0  \n",
       "10              0                   0           0       0           0  \n",
       "11              0                   0           0       1           0  \n",
       "12              0                   1           0       0           0  \n",
       "13              0                   0           0       1           0  \n",
       "14              0                   1           0       0           0  \n",
       "15              0                   0           0       1           1  \n",
       "16              1                   0           0       0           0  \n",
       "17              0                   0           0       0           0  \n",
       "18              1                   0           0       0           0  \n",
       "19              0                   1           0       0           1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the data direct from GitHub\n",
    "bank_df = pd.read_csv('../Data/UniversalBank.csv') # change this path depending on where you store the file on your computer\n",
    "bank_df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check column names, and for convenience, remove whitespaces..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ID', 'Age', 'Experience', 'Income', 'ZIP Code', 'Family', 'CCAvg',\n",
       "       'Education', 'Mortgage', 'Personal Loan', 'Securities Account',\n",
       "       'CD Account', 'Online', 'CreditCard'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bank_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ID', 'AGE', 'EXPERIENCE', 'INCOME', 'ZIP_CODE', 'FAMILY', 'CCAVG',\n",
       "       'EDUCATION', 'MORTGAGE', 'PERSONAL_LOAN', 'SECURITIES_ACCOUNT',\n",
       "       'CD_ACCOUNT', 'ONLINE', 'CREDITCARD'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bank_df.columns = [s.strip().upper().replace(' ', '_') for s in bank_df.columns] \n",
    "bank_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We decide that a couple of variables aren't predictors; therefore we drop them and then check if there are any missing values in the remaining variables..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AGE                   0\n",
       "EXPERIENCE            0\n",
       "INCOME                0\n",
       "FAMILY                0\n",
       "CCAVG                 0\n",
       "EDUCATION             0\n",
       "MORTGAGE              0\n",
       "PERSONAL_LOAN         0\n",
       "SECURITIES_ACCOUNT    0\n",
       "CD_ACCOUNT            0\n",
       "ONLINE                0\n",
       "CREDITCARD            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop ID, and Zip Code as predictors\n",
    "bank_df = bank_df.drop(columns=['ID', 'ZIP_CODE'])\n",
    "\n",
    "# check for missing values\n",
    "bank_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the variable types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AGE                     int64\n",
       "EXPERIENCE              int64\n",
       "INCOME                  int64\n",
       "FAMILY                  int64\n",
       "CCAVG                 float64\n",
       "EDUCATION               int64\n",
       "MORTGAGE                int64\n",
       "PERSONAL_LOAN           int64\n",
       "SECURITIES_ACCOUNT      int64\n",
       "CD_ACCOUNT              int64\n",
       "ONLINE                  int64\n",
       "CREDITCARD              int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bank_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bank_df.SECURITIES_ACCOUNT.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "bank_df.SECURITIES_ACCOUNT = bank_df.SECURITIES_ACCOUNT.astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bank_df.CD_ACCOUNT.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "bank_df.CD_ACCOUNT = bank_df.CD_ACCOUNT.astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bank_df.ONLINE.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "bank_df.ONLINE = bank_df.ONLINE.astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bank_df.CREDITCARD.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "bank_df.CREDITCARD = bank_df.CREDITCARD.astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bank_df.PERSONAL_LOAN.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "bank_df.PERSONAL_LOAN = bank_df.PERSONAL_LOAN.astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bank_df.EDUCATION.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "bank_df.EDUCATION = bank_df.EDUCATION.astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AGE</th>\n",
       "      <th>EXPERIENCE</th>\n",
       "      <th>INCOME</th>\n",
       "      <th>FAMILY</th>\n",
       "      <th>CCAVG</th>\n",
       "      <th>MORTGAGE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>45.338400</td>\n",
       "      <td>20.104600</td>\n",
       "      <td>73.774200</td>\n",
       "      <td>2.396400</td>\n",
       "      <td>1.937938</td>\n",
       "      <td>56.498800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>11.463166</td>\n",
       "      <td>11.467954</td>\n",
       "      <td>46.033729</td>\n",
       "      <td>1.147663</td>\n",
       "      <td>1.747659</td>\n",
       "      <td>101.713802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>23.000000</td>\n",
       "      <td>-3.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>35.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>45.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>55.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>98.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>101.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>67.000000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>224.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>635.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               AGE   EXPERIENCE       INCOME       FAMILY        CCAVG  \\\n",
       "count  5000.000000  5000.000000  5000.000000  5000.000000  5000.000000   \n",
       "mean     45.338400    20.104600    73.774200     2.396400     1.937938   \n",
       "std      11.463166    11.467954    46.033729     1.147663     1.747659   \n",
       "min      23.000000    -3.000000     8.000000     1.000000     0.000000   \n",
       "25%      35.000000    10.000000    39.000000     1.000000     0.700000   \n",
       "50%      45.000000    20.000000    64.000000     2.000000     1.500000   \n",
       "75%      55.000000    30.000000    98.000000     3.000000     2.500000   \n",
       "max      67.000000    43.000000   224.000000     4.000000    10.000000   \n",
       "\n",
       "          MORTGAGE  \n",
       "count  5000.000000  \n",
       "mean     56.498800  \n",
       "std     101.713802  \n",
       "min       0.000000  \n",
       "25%       0.000000  \n",
       "50%       0.000000  \n",
       "75%     101.000000  \n",
       "max     635.000000  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bank_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Split Data\n",
    "\n",
    "Split data into a 70/30 split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, validation_df = train_test_split(bank_df, test_size=0.3, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Address Data Imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3169 331\n"
     ]
    }
   ],
   "source": [
    "non_loan_count, loan_count = train_df.PERSONAL_LOAN.value_counts()\n",
    "print(non_loan_count, loan_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Oversampling Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "took_loan_df  = train_df.loc[train_df.PERSONAL_LOAN==1]\n",
    "df_oversampled = took_loan_df.sample(n=(non_loan_count-loan_count),replace=True)\n",
    "\n",
    "train_df = pd.concat([train_df, df_oversampled], ignore_index=True)\n",
    "train_df.PERSONAL_LOAN.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Undersampling Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "took_loan_df = train_df.loc[train_df.PERSONAL_LOAN==1]\n",
    "did_not_take_loan_df  = train_df.loc[train_df.PERSONAL_LOAN==0]\n",
    "\n",
    "df_undersampled = did_not_take_loan_df.sample(n=(loan_count),replace=False)\n",
    "\n",
    "train_df = pd.concat([took_loan_df, df_undersampled], ignore_index=True)\n",
    "train_df.PERSONAL_LOAN.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mixing Over and Under sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "did_not_take_loan_df  = train_df.loc[train_df.PERSONAL_LOAN==0]\n",
    "took_loan_df  = train_df.loc[train_df.PERSONAL_LOAN==1]\n",
    "\n",
    "num_of_observations = train_df.shape[0]\n",
    "print(num_of_observations//2)\n",
    "\n",
    "df_undersampled = did_not_take_loan_df.sample(n=(num_of_observations//2),replace=False)\n",
    "df_oversampled = took_loan_df.sample(n=(num_of_observations//2),replace=True)\n",
    "\n",
    "train_df = pd.concat([df_undersampled, df_oversampled], ignore_index=True)\n",
    "train_df.PERSONAL_LOAN.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform Predictors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K-nn models are sensitive to differences in scale; therefore, we should begin by eliminating any differences in scale between the predictors/features. To accomplish this, we will standardize the values of each variable.\n",
    "\n",
    "We will use the popular sklearn library's 'standard scaler' to accomplish this. This library contains many of the common functions we require when conducting analytics. The standard scaler function will standardize our variables. To achieve this, we will first need to train the scaler on the training data and then apply this trained scaler to standardize both the training and validation sets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'PERSONAL_LOAN'\n",
    "predictors = list(bank_df.columns)\n",
    "predictors.remove(target)\n",
    "\n",
    "# create a standard scaler and fit it to the training set of predictors\n",
    "scaler = preprocessing.StandardScaler()\n",
    "scaler.fit(train_df[predictors])\n",
    "\n",
    "# Transform the predictors of training and validation sets\n",
    "train_predictors = scaler.transform(train_df[predictors]) # train_predictors is not a numpy array\n",
    "train_target = train_df[target] # train_target is now a series object\n",
    "\n",
    "validation_predictors = scaler.transform(validation_df[predictors]) # validation_target is now a series object\n",
    "validation_target = validation_df[target] # validation_target is now a series object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> * https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html\n",
    "> * https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now explore the results of the standardization (NOTE: The returned object from a scaler transform is a numpy array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.85243239  0.78800252 -1.18974485  1.31706952 -0.16234237 -1.28425872\n",
      "  -0.57107278  2.68625435 -0.47937063 -1.25969998 -0.68419354]\n",
      " [-1.1205638  -1.18463806 -0.5240144  -1.33678386  0.02650939  1.12781829\n",
      "  -0.57107278 -0.37226557 -0.47937063 -1.25969998 -0.68419354]\n",
      " [ 1.45290949  1.47413838 -1.2637149  -1.33678386 -0.82332354  1.12781829\n",
      "  -0.57107278 -0.37226557 -0.47937063  0.79383981 -0.68419354]\n",
      " [ 1.62447438  1.55990536 -1.43014752  0.43245173 -1.0121753  -0.07822021\n",
      "  -0.57107278 -0.37226557 -0.47937063  0.79383981 -0.68419354]\n",
      " [ 0.76664995  0.78800252 -0.8198946   1.31706952  0.45142586 -0.07822021\n",
      "   0.55321355 -0.37226557 -0.47937063  0.79383981 -0.68419354]]\n",
      "\n",
      "[0 0 0 0 0]\n",
      "\n",
      "[[-1.20634624 -1.27040504 -0.41305933 -1.33678386  0.02650939  1.12781829\n",
      "   0.22120953 -0.37226557 -0.47937063 -1.25969998  1.46157474]\n",
      " [-0.86321647 -0.92733711 -1.13426732  0.43245173 -0.91774942 -1.28425872\n",
      "   0.19102735  2.68625435 -0.47937063 -1.25969998 -0.68419354]\n",
      " [-0.94899891 -0.92733711 -1.31919244  0.43245173 -0.72889766 -1.28425872\n",
      "  -0.57107278 -0.37226557 -0.47937063 -1.25969998 -0.68419354]\n",
      " [ 0.33773773  0.27340063  0.14171605 -1.33678386 -1.20102707 -1.28425872\n",
      "   1.58695333 -0.37226557 -0.47937063  0.79383981 -0.68419354]\n",
      " [-0.77743403 -0.67003617 -0.6719545   0.43245173 -0.11512943 -0.07822021\n",
      "   0.67394228 -0.37226557 -0.47937063  0.79383981 -0.68419354]]\n",
      "\n",
      "[0 0 0 0 0]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "print(train_predictors[:5], end=\"\\n\\n\")\n",
    "print(np.array(train_target[:5]), end=\"\\n\\n\")\n",
    "print(validation_predictors[:5], end=\"\\n\\n\")\n",
    "print(np.array(validation_target[:5]), end=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Train a K-NN model\n",
    "\n",
    "You've heard that a good starting point in determining a k value is to try the square root of the total observations. Since there are 5000 observations, following this rule of thumb, we would select a k value of 70  (but it's best to choose an odd number so that we will use k=71).\n",
    "\n",
    "> If k is an even number, there is a possibility that an observation could have the same number of nearest neighbors being one class (they took the loan) as the number being another (did not take the loan). In the cases of a tie, the SKLearn implementation of k-nn will select the first found. Though the chances of this happening are low, it's better to avoid this by choosing an odd number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=71,  metric='euclidean') # user euclidean distance\n",
    "\n",
    "# We could choose other distance metrics; for a list of other metrics...\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.metrics.pairwise.distance_metrics.html#sklearn.metrics.pairwise.distance_metrics\n",
    "# coverage of difference distance metrics is outside of this courses scope... but, you can experiment by changing the metric\n",
    "# for example...\n",
    "#knn = KNeighborsClassifier(n_neighbors=71,  metric='manhattan')\n",
    "\n",
    "knn.fit(train_predictors, train_target)\n",
    "knn_prediction_output = knn.predict(validation_predictors)\n",
    "knn_prediction_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "> * https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html\n",
    "> * https://scikit-learn.org/stable/modules/generated/sklearn.metrics.DistanceMetric.html#sklearn.metrics.DistanceMetric\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 1235, 1: 265}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique, counts = np.unique(knn_prediction_output, return_counts=True)\n",
    "dict(zip(unique, counts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Note that we know that the TP rate is 480/5000 = 9.6% in the sample, but our predictions are identifying 41/1459=2.8%. This is a bit of a 'red flag' to indicate that the precision of our model may be poor - which is most likely due to the imbalance between classes in our training data (480 in one class and 4520 in the other). Such imbalances can be a problem with many machine learning algorithms, including k-nn. Addressing this problem is a topic for another class, but the influence of the unbalanced data can be partially mitigated by using a smaller k value. We will see this in practice when we cover hyper-parameter tuning in the next class.\n",
    "\n",
    "> For now, we will ignore this potential opportunity to improve our model and move ahead with our analysis to see if this model is sufficient to help Universal Bank generate profit. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hnRpvv2znmO6"
   },
   "source": [
    "## Measure performance of model using confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "id": "wdGfPJfEYlRV",
    "outputId": "2fe22ed5-6d97-40cf-88e0-09f8f8cee8f4"
   },
   "outputs": [],
   "source": [
    "confusion = confusion_matrix(validation_target, knn_prediction_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> * https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1216,  135],\n",
       "       [  19,  130]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "5ulijKuInH4J"
   },
   "outputs": [],
   "source": [
    "TP = confusion[1, 1] # True Positives\n",
    "TN = confusion[0, 0] # True Negatives\n",
    "FP = confusion[0, 1] # False Positives\n",
    "FN = confusion[1, 0] # False Negatives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f8RSxiWGnJj2"
   },
   "source": [
    "### Accuracy:\n",
    "\n",
    "How often was the model correct?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "FfO1nisznIiI",
    "outputId": "878d0f2f-3f3a-41c7-9b9e-d0f428fb950e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8973\n"
     ]
    }
   ],
   "source": [
    "classification_accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
    "print(f\"{classification_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qZGZKw3bnMye"
   },
   "source": [
    "### Misclassification Rate:\n",
    "\n",
    "How often was the model incorrect?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "id": "1YLQMVIVnMC_",
    "outputId": "8bfe3f91-530d-421f-aeda-5a53febf6635"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1027\n"
     ]
    }
   ],
   "source": [
    "classification_error = (FP + FN) / (TP + TN + FP + FN)\n",
    "# this is the same as ...\n",
    "# classification_error = 1-classification_accuracy\n",
    "\n",
    "print(f\"{classification_error:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SzKkssIbnPXd"
   },
   "source": [
    "### Precision: \n",
    "\n",
    "When a positive value is predicted, how often is the prediction correct?\n",
    "\n",
    "In other wordes: How \"precise\" is the classifier when predicting positive instances?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "DE2o7HIxnP7F",
    "outputId": "cc8b3fe4-0e6e-428a-9907-e46e8e7d007e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4906\n"
     ]
    }
   ],
   "source": [
    "precision = TP / (TP + FP)\n",
    "print(f\"{precision:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tjSqr2r2nQPm"
   },
   "source": [
    "### Recall (aka sensititivy):\n",
    "\n",
    "Ability of a classification model to identify all relevant instances. \n",
    "Also referred to as Sensitivity, Probability of Detection, True Positive Rate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "DT7oM6VtoVuq",
    "outputId": "974479f7-52d7-4550-a4a3-d3556fe03f81"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8725\n"
     ]
    }
   ],
   "source": [
    "recall = TP / (TP + FN)\n",
    "print(f\"{recall:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hK9rHhz8nPk8"
   },
   "source": [
    "### F1 Score\n",
    "\n",
    "This is a measure that takes the harmonic mean of precision and recall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "cXVb-Q59ox_k",
    "outputId": "ee546904-3955-492b-b0aa-b13cf06aacf4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6280\n"
     ]
    }
   ],
   "source": [
    "f1_Score = (2 * precision * recall) / (precision + recall)\n",
    "print(f\"{f1_Score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* As the analytics consultant, you know what all the above performance measures mean - but while presenting this information to the CEO, she became impatient and interrupted you to ask how profit and loss will be impacted if they choose to use this model over simply targeting everyone (you then take a note to yourself to place more focus on profit and loss when speaking with future CEO's)*\n",
    "\n",
    "Let's look at how we could address this question..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Is our k-nn model a better model that the null (promote to all) model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Based on your initial business problem scoping, you calculated Universal Bank's expected profit from targeting the remaining 50,000 customers without the support of a model was \\\\$-20,000.00. \n",
    "\n",
    "Let's calculate how much our model improves things..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What would be the expected returns from not using a model?\n",
    "\n",
    "From the initial trial, 480 of the 5000 (9.6%) customers targeted took the loan, and 5000-480 (90.4%) didn't take the loan. Since the initial test was on a random selection of customers and did not use a model, then the expected percentage of the 50000 customer will also be 9.6% and 90.4%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the confusion matrix of the performance of the model on the validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1216,  135],\n",
       "       [  19,  130]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's convert these values into percentages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.81066667, 0.09      ],\n",
       "       [0.01266667, 0.08666667]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_perc = confusion/(.3*5000)  # since the confusion matrix is for the performance on the validation data, it's .30% of 5000, or 1500. \n",
    "confusion_perc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's do a scaler multiplication of the number of customers that will be targetted in the newly proposed campaign (50,000 customers). This will give us the number of expected customers in each of the categories in the confusion matrix (TP, FP, TN, FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[40533.33333333,  4500.        ],\n",
       "       [  633.33333333,  4333.33333333]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_result = confusion_perc * 50000\n",
    "knn_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's create a p_and_l matrix (profit and loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,  -10],\n",
       "       [-100,   90]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_and_l = np.array([[TN_profit, FP_profit],[FN_profit, TP_profit]])\n",
    "p_and_l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multiple our profit and loss matrix with our knn_result matrix to get profit and loss associated with each of the catgories (FP, TP, FN, TN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[     0.        , -45000.        ],\n",
       "       [-63333.33333333, 390000.        ]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_result * p_and_l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get the total profit, we simply need to sum up all the p_and_l's for each category (TP, FP, TN, FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$281,666.67\n"
     ]
    }
   ],
   "source": [
    "model_profit = (knn_result * p_and_l).sum()\n",
    "\n",
    "print(f\"${model_profit:,.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, using a k value of 71 would result in a model that is expected to look over \\\\$250,000 in the upcoming campaign. This is much worse than the null model (where they simply don't use a model and target every customer)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing other values of k\n",
    "\n",
    "Clearly, our model is a failure. Despite some model measures seemingly looking ok (for instance, accuracy is 92.53%), using it would result in an expected loss of \\\\$250,333.33 (good thing we checked!). \n",
    "\n",
    "Let's spend a few minutes thinking about why that is.\n",
    "\n",
    "Notice that though accuracy looks quite good, recall is relatively poor. Since the cost of an FN is very high (loss of \\\\$100) relative to the cost of a false positive (a loss of \\\\$$10), the distribution of the misclassified observations between FP and FN is very important. For any errors we must accept, it is much more advantageous if these are FP's. \n",
    "\n",
    "As we noted in the early stages of this evaluation (see note in \"Train a K-NN model\" section), our dataset is significantly unbalanced, with the number of customers not taking a loan nearly 10x higher than those that would take a loan. K-NN is particularly sensitive to this; in this case, the more significant proportion of observations where the customer did not take a loan makes it difficult for K-NN to identify the instances where they would take a loan. (since it's much more probably that a neighbor is a non-customer, and thus the voting will skew towards selecting an observation as a non-customer). This is particularly more problematic as the value of k increases. \n",
    "\n",
    "Is all lost?\n",
    "\n",
    "There is still a chance that we can make the model better. Due to the unbalanced nature of this dataset, we'll most likely find that the model will perform better with a lower value of k. \n",
    "\n",
    "Let's test this hypothesis by trying a range of k values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For k=1 model profit is $201,000.00\n",
      "For k=3 model profit is $251,000.00\n",
      "For k=5 model profit is $294,000.00\n",
      "For k=7 model profit is $304,666.67\n",
      "For k=9 model profit is $290,333.33\n",
      "For k=11 model profit is $319,000.00\n",
      "For k=13 model profit is $328,333.33\n",
      "For k=15 model profit is $317,666.67\n",
      "For k=17 model profit is $327,666.67\n",
      "For k=19 model profit is $326,333.33\n",
      "For k=21 model profit is $320,666.67\n",
      "For k=23 model profit is $320,000.00\n",
      "For k=25 model profit is $326,333.33\n",
      "For k=27 model profit is $327,333.33\n",
      "For k=29 model profit is $315,333.33\n",
      "For k=31 model profit is $309,333.33\n",
      "For k=33 model profit is $309,000.00\n",
      "For k=35 model profit is $315,000.00\n",
      "For k=37 model profit is $320,333.33\n",
      "For k=39 model profit is $311,666.67\n",
      "For k=41 model profit is $316,000.00\n",
      "For k=43 model profit is $303,333.33\n",
      "For k=45 model profit is $296,333.33\n",
      "For k=47 model profit is $301,666.67\n",
      "For k=49 model profit is $301,666.67\n",
      "For k=51 model profit is $297,000.00\n",
      "For k=53 model profit is $297,000.00\n",
      "For k=55 model profit is $290,333.33\n",
      "For k=57 model profit is $291,000.00\n",
      "For k=59 model profit is $290,333.33\n",
      "For k=61 model profit is $289,000.00\n",
      "For k=63 model profit is $287,000.00\n",
      "For k=65 model profit is $291,333.33\n",
      "For k=67 model profit is $292,333.33\n",
      "For k=69 model profit is $293,000.00\n",
      "For k=71 model profit is $281,666.67\n",
      "For k=73 model profit is $287,000.00\n",
      "For k=75 model profit is $294,000.00\n",
      "For k=77 model profit is $294,000.00\n",
      "For k=79 model profit is $288,000.00\n",
      "For k=81 model profit is $296,666.67\n",
      "For k=83 model profit is $302,333.33\n",
      "For k=85 model profit is $294,333.33\n",
      "For k=87 model profit is $294,000.00\n",
      "For k=89 model profit is $294,666.67\n",
      "For k=91 model profit is $276,000.00\n",
      "For k=93 model profit is $276,000.00\n",
      "For k=95 model profit is $276,666.67\n",
      "For k=97 model profit is $276,666.67\n",
      "For k=99 model profit is $271,333.33\n",
      "For k=101 model profit is $271,333.33\n",
      "For k=103 model profit is $258,666.67\n",
      "For k=105 model profit is $258,333.33\n",
      "For k=107 model profit is $257,666.67\n",
      "For k=109 model profit is $264,000.00\n",
      "For k=111 model profit is $275,666.67\n",
      "For k=113 model profit is $270,333.33\n",
      "For k=115 model profit is $284,666.67\n",
      "For k=117 model profit is $277,333.33\n",
      "For k=119 model profit is $283,000.00\n",
      "For k=121 model profit is $269,666.67\n",
      "For k=123 model profit is $263,333.33\n",
      "For k=125 model profit is $271,000.00\n",
      "For k=127 model profit is $257,000.00\n",
      "For k=129 model profit is $270,666.67\n",
      "For k=131 model profit is $282,666.67\n",
      "For k=133 model profit is $283,333.33\n",
      "For k=135 model profit is $270,666.67\n",
      "For k=137 model profit is $270,000.00\n",
      "For k=139 model profit is $264,000.00\n",
      "********************************************************************************\n",
      "Max profit is 328,333.33\n",
      "********************************************************************************\n"
     ]
    }
   ],
   "source": [
    "profits = []\n",
    "for i in range(1,141,2):\n",
    "    knn = KNeighborsClassifier(n_neighbors=i,  metric='euclidean')\n",
    "    knn.fit(train_predictors, train_target)\n",
    "    knn_prediction_output = knn.predict(validation_predictors)\n",
    "    confusion = confusion_matrix(validation_target, knn_prediction_output)\n",
    "    TP = confusion[1, 1] \n",
    "    TN = confusion[0, 0] \n",
    "    FP = confusion[0, 1] \n",
    "    FN = confusion[1, 0] \n",
    "    confusion_perc = confusion/1500 \n",
    "    knn_result = confusion_perc * 50000\n",
    "    p_and_l = np.array([[TN_profit, FP_profit],[FN_profit, TP_profit]])\n",
    "    knn_result * p_and_l\n",
    "    model_profit = (knn_result * p_and_l).sum()\n",
    "    profits.append(model_profit)\n",
    "    print(f\"For k={i} model profit is ${model_profit:,.2f}\")\n",
    "print(\"*\"*80)    \n",
    "print(f\"Max profit is {max(profits):,.2f}\")\n",
    "print(\"*\"*80)    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Business Impact Summary\n",
    "\n",
    "> TODO: Add in your summary of the results\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "jKZWz5SKzGNE",
    "QICirRwAt0AL"
   ],
   "include_colab_link": true,
   "name": "Class05-KNN_with_CONFUSION_MATRIX.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
